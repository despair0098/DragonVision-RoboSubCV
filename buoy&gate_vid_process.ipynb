{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Imports__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [+] Libraries that are commented out are only for ROS\n",
    "#import rospy\n",
    "import numpy as np\n",
    "import cv2\n",
    "#from std_msgs.msg import Float64\n",
    "#from sensor_msgs.msg import Image\n",
    "#from cv_bridge import CvBridge, CvBridgeError\n",
    "import math\n",
    "import time\n",
    "\n",
    "#[+------:\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Gate__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "# [+]- Access the camera, the int parameter determines which camera you are using, may have to change in depending on what computer you run on\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "# video_capture = cv2.VideoCapture(1)\n",
    "# video_capture = cv2.VideoCapture(2)\n",
    "\n",
    "#[+]- Each iteration of this loop processes a frame that is captured by the camera by applying a series of filters. Each filter is in intermediate step, the final image is the one which we annotate and extract information from. \n",
    "while(True):\n",
    "    # Capture the frames\n",
    "    ret, frame = video_capture.read()\n",
    "    final = frame\n",
    "\n",
    "    # change from bgr values to hsv values\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # color bounds of color to be filtered out [+] correction: colors to be NOT filtered out\n",
    "    # lower_color_bounds = np.array([0, 200, 0])\n",
    "    # upper_color_bounds = np.array([255, 255, 255])\n",
    "    lower_color_bounds = np.array([0, 100, 20])\n",
    "    upper_color_bounds = np.array([30, 255, 255])\n",
    "\n",
    "\n",
    "    # [+]- Filter 1: threshold shows in black the pixels being filtered out [+: show only the colors that are between the two bounds)\n",
    "    threshold = cv2.inRange(hsv, lower_color_bounds, upper_color_bounds)\n",
    "\n",
    "    #[+]- Filter 2:  erode to remove noise\n",
    "    kernel = np.ones((10, 10), np.uint8)\n",
    "    erode = cv2.erode(threshold, kernel)\n",
    "\n",
    "    # get the contours, Each individual contour is a Numpy array of (x,y) coordinates of boundary points of the object\n",
    "    contours = cv2.findContours(erode, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0]\n",
    "\n",
    "    # create bounding boxes, creates an array of contour areas so that we can know which is th ebiggest\n",
    "    contour_areas = [cv2.contourArea(x) for x in contours]  \n",
    "    \n",
    "    # get the areas of each contour, returns a list of indeces for contour areas array\n",
    "    contour_indexes = np.argsort(contour_areas)  \n",
    "    \n",
    "    # sort the indexes of the largest areas\n",
    "    for i in contour_indexes[-2:]:  # only look at the two largest contours\n",
    "        (x,y,w,h) = cv2.boundingRect(contours[i])  # get the location/dimensions of a bounding box for the contour: x,y=coordinates, w,h=dims\n",
    "        cv2.rectangle(final, pt1=(x,y), pt2=(x+w,y+h), color=(255,0,0), thickness=5)  # draw the bounding box on the image\n",
    "\n",
    "        # for visibility, we will place a background fill on the contour label\n",
    "        text = \"gatepost\"\n",
    "        text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, 1, 1)\n",
    "        text_w, text_h = text_size\n",
    "        cv2.rectangle(final, pt1=(x, y), pt2=(x + text_w, y - 2*text_h), color=(255, 0, 0), thickness=-1)\n",
    "        cv2.putText(final, \"gatepost\", org=(x, y-5), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=1, color=(255, 255, 255), thickness=1)\n",
    "\n",
    "    # [+]- Show each filter that is applied to the frame. Each filter is shown in a separate window\n",
    "    # cv2.imshow('1 Gate: original frame',frame)\n",
    "    cv2.imshow('2 Gate: threshold', threshold)\n",
    "    cv2.imshow(\"3 Gate: eroded\", erode)\n",
    "    cv2.imshow(\"4 Gate: final\", final)\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Buoy__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "# [+]- Access the camera, the int parameter determines which camera you are using, may have to change in depending on what computer you run on\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "# video_capture = cv2.VideoCapture(1)\n",
    "# video_capture = cv2.VideoCapture(2)\n",
    "\n",
    "# # color bounds of color to be [NOT] filtered out, by default it filters out light colors so that it can identif \n",
    "lower_value_bounds = np.array([0, 0, 0])\n",
    "upper_value_bounds = np.array([255, 255, 45])\n",
    "\n",
    "\n",
    "#[+:]-- -------------------------------------------------//\n",
    "lower_value_bounds2 = np.array([0, 0, 0])\n",
    "upper_value_bounds2 = np.array([255, 255, 80])\n",
    "clk= 0\n",
    "clkRate= 9\n",
    "clkLim= clkRate*255\n",
    "#-------------------------------------------------------//\n",
    "\n",
    "dilateKernel = np.ones((5, 5), np.uint8)\n",
    "erodeKernel = np.ones((10, 10), np.uint8)\n",
    "erodeKernel2= np.ones((6, 6), np.uint8)\n",
    "blurnel = (5, 5)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    # Capture the frames\n",
    "    ret, img_frame = video_capture.read()\n",
    "    img_final = img_frame\n",
    "\n",
    "    # change from bgr values to hsv values\n",
    "    img_hsv = cv2.cvtColor(img_frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # threshold shows in black the pixels being filtered out\n",
    "    img_threshold = cv2.inRange(img_hsv, lower_value_bounds, upper_value_bounds)\n",
    "\n",
    "    #  [+:] -- Use this to find the ideal value range, which changes depending on the lighting ----------//\n",
    "    tick= clk//clkRate\n",
    "    # img_threshold = cv2.inRange(img_hsv, np.array([0, 0, 0]), np.array([255, 255, tick]))\n",
    "    # cv2.putText(img_final, \"[:+:] CLK: \"+ str(tick), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.7, color=(200, 150, 0), thickness=2)\n",
    "    # clk+= 1\n",
    "    # if clk>clkLim: clk=0\n",
    "    #-----------------------------------------------------------------------------------------------------//\n",
    "\n",
    "    # dilate to combine contours\n",
    "    img_dilate = cv2.dilate(img_threshold, dilateKernel, iterations=3)\n",
    "\n",
    "    # erode to remove noise\n",
    "    img_erode = cv2.erode(img_dilate, erodeKernel, iterations=2)\n",
    "\n",
    "    # blur to smooth edges so circle detection is easier\n",
    "    img_blur = cv2.blur(img_erode, ksize= blurnel)\n",
    "\n",
    "    # detect circles\n",
    "    circles = cv2.HoughCircles(img_blur, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                  param1=30,  # edge detection parameter\n",
    "                  param2=30,  # accumulator threshold, or how circley the circles need to be to be recognized (higher=more circlely)\n",
    "                  minRadius=0,\n",
    "                  maxRadius=100)\n",
    "\n",
    "    # if a circle is identified\n",
    "    if (type(circles)) is np.ndarray:\n",
    "        # draw the circles\n",
    "        circle_radii = [x[2] for x in circles[0]]  # get the radii of each contour\n",
    "        circle_indexes = np.argsort(circle_radii)  # sort by largest radius\n",
    "        for i in circle_indexes[-2:]:  # only contour at the largest circles\n",
    "            circle = circles[0][i]  # get the largest circle\n",
    "            cv2.circle(img_final, center=(int(circle[0]), int(circle[1])), radius=int(circle[2]), color=(100, 0, 255), thickness=2)  # draw the circle on the image\n",
    "            # make the text centered\n",
    "            # text = \"police buoy\"\n",
    "            text = \" --  -- \"\n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, 1, 1)  # get the text size\n",
    "            text_w, text_h = text_size  # get the text width/height\n",
    "            cv2.putText(img_final, text, org=(int(circle[0])-text_w, int(circle[1])+(text_h//2)+8), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=2, color=(100, 0, 255), thickness=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #[:+:]===============================================================================================================================================[:+:]\n",
    "    clkRate= 1\n",
    "    #[+]-------- ----------------------------------------------------------------------------//\n",
    "    img_threshold2 = cv2.inRange(img_hsv, np.array([0, 0, 0]), np.array([255, 255, 80]))\n",
    "    cv2.putText(img_final, (\"[:+:] CLK: \"+ str(tick)), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.7, color=(100, 255, 100), thickness=2)\n",
    "    clk+= 1\n",
    "    if clk>clkLim: clk=0\n",
    "    #----------------------------------------------------------------------------------------//\n",
    "\n",
    "    img_erode2 = cv2.erode(img_threshold2, erodeKernel2, iterations=1)\n",
    "\n",
    "    dilateKernel2 = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    img_dilate2 = cv2.dilate(img_erode2, dilateKernel2, iterations=3)\n",
    "\n",
    "    img_blur2 = cv2.blur(img_erode2, ksize=blurnel)\n",
    "\n",
    "    circles2 = cv2.HoughCircles(img_blur2, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                  param1=30,  # edge detection parameter\n",
    "                  param2=30,  # accumulator threshold, or how circley the circles need to be to be recognized (higher=more circlely)\n",
    "                  minRadius=0,\n",
    "                  maxRadius=100)\n",
    "\n",
    "    #[+:] --- Circle Array # 2 ----------\n",
    "    if (type(circles2)) is np.ndarray:\n",
    "        circle_radii = [x[2] for x in circles2[0]]  \n",
    "        circle_indexes = np.argsort(circle_radii)  \n",
    "        for i in circle_indexes[-2:]:  \n",
    "            circle = circles2[0][i] \n",
    "            cv2.circle(img_final, center=(int(circle[0]), int(circle[1])), radius=int(circle[2])+25, color=(200, 150, 0), thickness=2) \n",
    "            text = \"[:+:]\"\n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_DUPLEX, 1, 1)  \n",
    "            text_w, text_h = text_size  \n",
    "            cv2.putText(img_final, text, org=(int(circle[0])-text_w, int(circle[1])+text_h), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=2, color=(200, 150, 0), thickness=2)\n",
    "    #[:\\:]===============================================================================================================================================[:\\:]\n",
    "\n",
    "\n",
    "\n",
    "    # [+] show frames\n",
    "    # cv2.imshow('1 original frame', img_frame)\n",
    "    # cv2.imshow('2 Buoy: hsv', img_hsv)\n",
    "    # cv2.imshow('3 Buoy: threshold', img_threshold)\n",
    "    # cv2.imshow(\"4 Buoy: dilated\", img_dilate)\n",
    "    # cv2.imshow(\"5 Buoy: eroded\", img_erode)\n",
    "    # cv2.imshow(\"6 Buoy: blur\", img_blur)\n",
    "    # cv2.imshow(\"7 Buoy: final\", img_final)\n",
    "\n",
    "    #[+: ------------------------------------------------- ::\n",
    "    # cv2.imshow('1 original frame2', img_frame)\n",
    "    # cv2.imshow('2 Buoy: hsv2', img_hsv)\n",
    "    cv2.imshow('3 Buoy: threshold2', img_threshold2)\n",
    "    cv2.imshow(\"4 Buoy: dilated2\", img_dilate2)\n",
    "    cv2.imshow(\"5 Buoy: eroded2\", img_erode2)\n",
    "    # cv2.imshow(\"6 Buoy: blur2\", img_blur2)\n",
    "    #::-----------------------------------------------------:+]\n",
    "    cv2.imshow(\"7 Buoy: final2\", img_final)\n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  __[:+:] Text Detection__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "# [+]- Access the camera, the int parameter determines which camera you are using, may have to change in depending on what computer you run on\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "# video_capture = cv2.VideoCapture(1)\n",
    "# video_capture = cv2.VideoCapture(2)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = video_capture.read()\n",
    "    final = frame\n",
    "\n",
    "    #--option 1: use grayscale-----\n",
    "    img2gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    ret, grayMask = cv2.threshold(img2gray, 180, 255, cv2.THRESH_BINARY)\n",
    "    imgFinal_gray = cv2.bitwise_and(img2gray, img2gray, mask=grayMask)\n",
    "\n",
    "    #---Option 2: use hsv---\n",
    "    img2hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    lower = np.array([0, 0, 218])\n",
    "    upper = np.array([157, 54, 255])\n",
    "    hsvMask = cv2.inRange(img2hsv, lower, upper)\n",
    "    # imgFinal_hsv = \n",
    "\n",
    "\n",
    "\n",
    "    # for black text , cv.THRESH_BINARY_INV\n",
    "    #ret, new_img = cv2.threshold(imgFinal_gray, 180, 255, cv2.THRESH_BINARY)  \n",
    "    ret, new_img = cv2.threshold(imgFinal_gray, 180, 255, cv2.THRESH_BINARY_INV)  \n",
    "\n",
    "\n",
    "\n",
    "    # to manipulate the orientation of dilution , large x means horizonatally dilating  more, large y means vertically dilating more\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))  \n",
    "\n",
    "    # dilate , more the iteration more the dilation\n",
    "    dilated = cv2.dilate(new_img, kernel, iterations=9)  \n",
    "\n",
    "\n",
    "    # for cv2.x.x: \n",
    "    # _, contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)  # findContours returns 3 variables for getting contours\n",
    "\n",
    "    # for cv3.x.x  comment above line and uncomment line below:\n",
    "    #image, contours, hierarchy = cv2.findContours(dilated,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # [::]-- Selection: \n",
    "    contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    for contour in contours:\n",
    "        # get rectangle bounding contour\n",
    "        [x, y, w, h] = cv2.boundingRect(contour)\n",
    "\n",
    "        # Don't plot small false positives that aren't text\n",
    "        if w < 35 and h < 35:\n",
    "            continue\n",
    "\n",
    "        # draw rectangle around contour on original image\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 255), 2)\n",
    "\n",
    " \n",
    "    #cv2.imshow('original frame',frame)\n",
    "    #cv2.imshow('threshold', imgFinal_gray)\n",
    "    #cv2.imshow(\"dilated\", dilated)\n",
    "    cv2.imshow(\"grayMask\", grayMask)\n",
    "    #cv2.imshow(\"hsvMask\", hsvMask)\n",
    "    cv2.imshow(\"new\", new_img)\n",
    "    cv2.imshow(\"final\", final)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10065f837bc8873f5387f5268b450066d881a20043fa6c000aa3f801fbe31849"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
