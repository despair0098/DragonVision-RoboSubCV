{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __[:+:] -- DragonVision Prototype-- [:+:]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [+] Libraries that are commented out are only for ROS\n",
    "#import rospy\n",
    "#from std_msgs.msg import Float64\n",
    "#from sensor_msgs.msg import Image\n",
    "#from cv_bridge import CvBridge, CvBridgeError\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "\n",
    "#[+------:\n",
    "import sys\n",
    "\n",
    "bgrRed= (0, 0, 255)\n",
    "bgrBlue= (255, 0, 0)\n",
    "bgrCyan= (200, 200, 50)\n",
    "bgrOrange= (100, 100, 255)\n",
    "bgrYellow= (75, 200, 255)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __[::] Gate (2022)__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "# [+]- Access the camera, the int parameter determines which camera you are using, may have to change in depending on what computer you run on\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "# video_capture = cv2.VideoCapture(1)\n",
    "# video_capture = cv2.VideoCapture(2)\n",
    "\n",
    "#[+]- Each iteration of this loop processes a frame that is captured by the camera by applying a series of filters. Each filter is in intermediate step, the final image is the one which we annotate and extract information from. \n",
    "while(True):\n",
    "    # Capture the frames\n",
    "    ret, frame = video_capture.read()\n",
    "    final = frame\n",
    "\n",
    "    # change from bgr values to hsv values\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # color bounds of color to be filtered out [+] correction: colors to be NOT filtered out\n",
    "    # lower_color_bounds = np.array([0, 200, 0])\n",
    "    # upper_color_bounds = np.array([255, 255, 255])\n",
    "    lower_color_bounds = np.array([0, 100, 20])\n",
    "    upper_color_bounds = np.array([30, 255, 255])\n",
    "\n",
    "\n",
    "    # [+]- Filter 1: threshold shows in black the pixels being filtered out [+: show only the colors that are between the two bounds)\n",
    "    threshold = cv2.inRange(hsv, lower_color_bounds, upper_color_bounds)\n",
    "\n",
    "    #[+]- Filter 2:  erode to remove noise\n",
    "    kernel = np.ones((10, 10), np.uint8)\n",
    "    erode = cv2.erode(threshold, kernel)\n",
    "\n",
    "    # get the contours, Each individual contour is a Numpy array of (x,y) coordinates of boundary points of the object\n",
    "    contours = cv2.findContours(erode, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0]\n",
    "\n",
    "    # create bounding boxes, creates an array of contour areas so that we can know which is th ebiggest\n",
    "    contour_areas = [cv2.contourArea(x) for x in contours]  \n",
    "    \n",
    "    # get the areas of each contour, returns a list of indeces for contour areas array\n",
    "    contour_indexes = np.argsort(contour_areas)  \n",
    "    \n",
    "    # sort the indexes of the largest areas\n",
    "    for i in contour_indexes[-2:]:  # only look at the two largest contours\n",
    "        (x,y,w,h) = cv2.boundingRect(contours[i])  # get the location/dimensions of a bounding box for the contour: x,y=coordinates, w,h=dims\n",
    "        cv2.rectangle(final, pt1=(x,y), pt2=(x+w,y+h), color=(255,0,0), thickness=5)  # draw the bounding box on the image\n",
    "\n",
    "        # for visibility, we will place a background fill on the contour label\n",
    "        text = \"gatepost\"\n",
    "        text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, 1, 1)\n",
    "        text_w, text_h = text_size\n",
    "        cv2.rectangle(final, pt1=(x, y), pt2=(x + text_w, y - 2*text_h), color=(255, 0, 0), thickness=-1)\n",
    "        cv2.putText(final, \"gatepost\", org=(x, y-5), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=1, color=(255, 255, 255), thickness=1)\n",
    "\n",
    "    # [+]- Show each filter that is applied to the frame. Each filter is shown in a separate window\n",
    "    # cv2.imshow('1 Gate: original frame',frame)\n",
    "    cv2.imshow('2 Gate: threshold', threshold)\n",
    "    cv2.imshow(\"3 Gate: eroded\", erode)\n",
    "    cv2.imshow(\"4 Gate: final\", final)\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __[::] Buoy (2022)__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27872/2551703912.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# [+]- Access the camera, the int parameter determines which camera you are using, may have to change in depending on what computer you run on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mvideo_capture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# video_capture = cv2.VideoCapture(1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# video_capture = cv2.VideoCapture(2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "# [+]- Access the camera, the int parameter determines which camera you are using, may have to change in depending on what computer you run on\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "# video_capture = cv2.VideoCapture(1)\n",
    "# video_capture = cv2.VideoCapture(2)\n",
    "\n",
    "# # color bounds of color to be [NOT] filtered out, by default it filters out light colors so that it can identif \n",
    "lower_value_bounds = np.array([0, 0, 0])\n",
    "upper_value_bounds = np.array([255, 255, 45])\n",
    "\n",
    "\n",
    "#[+:]-- -------------------------------------------------//\n",
    "lower_value_bounds2 = np.array([0, 0, 0])\n",
    "upper_value_bounds2 = np.array([255, 255, 80])\n",
    "clk= 0\n",
    "clkRate= 9\n",
    "clkLim= clkRate*255\n",
    "#-------------------------------------------------------//\n",
    "\n",
    "dilateKernel = np.ones((5, 5), np.uint8)\n",
    "erodeKernel = np.ones((10, 10), np.uint8)\n",
    "erodeKernel2= np.ones((6, 6), np.uint8)\n",
    "blurnel = (5, 5)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    # Capture the frames\n",
    "    ret, img_frame = video_capture.read()\n",
    "    img_final = img_frame\n",
    "\n",
    "    # change from bgr values to hsv values\n",
    "    img_hsv = cv2.cvtColor(img_frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "\n",
    "    # threshold shows in black the pixels being filtered out\n",
    "    img_threshold = cv2.inRange(img_hsv, lower_value_bounds, upper_value_bounds)\n",
    "\n",
    "    #  [+:] -- Use this to find the ideal value range, which changes depending on the lighting ----------//\n",
    "    tick= clk//clkRate\n",
    "    # img_threshold = cv2.inRange(img_hsv, np.array([0, 0, 0]), np.array([255, 255, tick]))\n",
    "    # cv2.putText(img_final, \"[:+:] CLK: \"+ str(tick), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.7, color=(200, 150, 0), thickness=2)\n",
    "    # clk+= 1\n",
    "    # if clk>clkLim: clk=0\n",
    "    #-----------------------------------------------------------------------------------------------------//\n",
    "\n",
    "    # dilate to combine contours\n",
    "    img_dilate = cv2.dilate(img_threshold, dilateKernel, iterations=3)\n",
    "\n",
    "    # erode to remove noise\n",
    "    img_erode = cv2.erode(img_dilate, erodeKernel, iterations=2)\n",
    "\n",
    "    # blur to smooth edges so circle detection is easier\n",
    "    img_blur = cv2.blur(img_erode, ksize= blurnel)\n",
    "\n",
    "    # detect circles\n",
    "    circles = cv2.HoughCircles(img_blur, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                  param1=30,  # edge detection parameter\n",
    "                  param2=30,  # accumulator threshold, or how circley the circles need to be to be recognized (higher=more circlely)\n",
    "                  minRadius=0,\n",
    "                  maxRadius=100)\n",
    "\n",
    "    # if a circle is identified\n",
    "    if (type(circles)) is np.ndarray:\n",
    "        # draw the circles\n",
    "        circle_radii = [x[2] for x in circles[0]]  # get the radii of each contour\n",
    "        circle_indexes = np.argsort(circle_radii)  # sort by largest radius\n",
    "        for i in circle_indexes[-2:]:  # only contour at the largest circles\n",
    "            circle = circles[0][i]  # get the largest circle\n",
    "            cv2.circle(img_final, center=(int(circle[0]), int(circle[1])), radius=int(circle[2]), color=(100, 0, 255), thickness=2)  # draw the circle on the image\n",
    "            # make the text centered\n",
    "            # text = \"police buoy\"\n",
    "            text = \" --  -- \"\n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, 1, 1)  # get the text size\n",
    "            text_w, text_h = text_size  # get the text width/height\n",
    "            cv2.putText(img_final, text, org=(int(circle[0])-text_w, int(circle[1])+(text_h//2)+8), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=2, color=(100, 0, 255), thickness=2)\n",
    "\n",
    "\n",
    "    #[:+:]===============================================================================================================================================[:+:]\n",
    "    clkRate= 1\n",
    "    #[+]-------- ----------------------------------------------------------------------------//\n",
    "    img_threshold2 = cv2.inRange(img_hsv, np.array([0, 0, 0]), np.array([255, 255, 80]))\n",
    "    cv2.putText(img_final, (\"[:+:] CLK: \"+ str(tick)), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.7, color=(100, 255, 100), thickness=2)\n",
    "    clk+= 1\n",
    "    if clk>clkLim: clk=0\n",
    "    #----------------------------------------------------------------------------------------//\n",
    "\n",
    "    img_erode2 = cv2.erode(img_threshold2, erodeKernel2, iterations=1)\n",
    "\n",
    "    dilateKernel2 = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    img_dilate2 = cv2.dilate(img_erode2, dilateKernel2, iterations=3)\n",
    "\n",
    "    img_blur2 = cv2.blur(img_erode2, ksize=blurnel)\n",
    "\n",
    "    circles2 = cv2.HoughCircles(img_blur2, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                  param1=30,  # edge detection parameter\n",
    "                  param2=30,  # accumulator threshold, or how circley the circles need to be to be recognized (higher=more circlely)\n",
    "                  minRadius=0,\n",
    "                  maxRadius=100)\n",
    "\n",
    "#[+:] --- Circle Array # 2 -----------------------------------------\n",
    "    if (type(circles2)) is np.ndarray:\n",
    "        circle_radii = [x[2] for x in circles2[0]]  \n",
    "        circle_indexes = np.argsort(circle_radii)  \n",
    "        for i in circle_indexes[-2:]:  \n",
    "            circle = circles2[0][i] \n",
    "            cv2.circle(img_final, center=(int(circle[0]), int(circle[1])), radius=int(circle[2])+25, color=(200, 150, 0), thickness=2) \n",
    "            text = \"[:+:]\"\n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_DUPLEX, 1, 1)  \n",
    "            text_w, text_h = text_size  \n",
    "            cv2.putText(img_final, text, org=(int(circle[0])-text_w, int(circle[1])+text_h), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=2, color=(200, 150, 0), thickness=2)\n",
    "#[:\\:]===============================================================================================================================================[:\\:]\n",
    "\n",
    "\n",
    "\n",
    "    # [+] show frames\n",
    "    # cv2.imshow('1 original frame', img_frame)\n",
    "    # cv2.imshow('2 Buoy: hsv', img_hsv)\n",
    "    # cv2.imshow('3 Buoy: threshold', img_threshold)\n",
    "    # cv2.imshow(\"4 Buoy: dilated\", img_dilate)\n",
    "    # cv2.imshow(\"5 Buoy: eroded\", img_erode)\n",
    "    # cv2.imshow(\"6 Buoy: blur\", img_blur)\n",
    "    # cv2.imshow(\"7 Buoy: final\", img_final)\n",
    "\n",
    "    #[+: ------------------------------------------------- ::\n",
    "    # cv2.imshow('1 original frame2', img_frame)\n",
    "    # cv2.imshow('2 Buoy: hsv2', img_hsv)\n",
    "    cv2.imshow('3 Buoy: threshold2', img_threshold2)\n",
    "    cv2.imshow(\"4 Buoy: dilated2\", img_dilate2)\n",
    "    cv2.imshow(\"5 Buoy: eroded2\", img_erode2)\n",
    "    cv2.imshow(\"6 Buoy: blur2\", img_blur2)\n",
    "    #::-----------------------------------------------------:+]\n",
    "    cv2.imshow(\"7 Buoy: final2\", img_final)\n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __[::] Circle Detection__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "# [+]- Access the camera, the int parameter determines which camera you are using, may have to change in depending on what computer you run on\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "# video_capture = cv2.VideoCapture(1)\n",
    "# video_capture = cv2.VideoCapture(2)\n",
    "\n",
    "lower_value_bounds = np.array([0, 0, 0])\n",
    "upper_value_bounds = np.array([255, 255, 75])\n",
    "\n",
    "houghParam1=40\n",
    "houghParam2=45\n",
    "# houghParam1=15\n",
    "# houghParam2=30\n",
    "\n",
    "#[+:]-- -------------------------------------------------//\n",
    "clk= 0\n",
    "clkRate= 1\n",
    "clkLim= clkRate*255\n",
    "#-------------------------------------------------------//\n",
    "\n",
    "\n",
    "kernel_sqr = np.ones((1,1), np.uint8)\n",
    "kernel_3x1= np.ones((3,1), np.uint8)\n",
    "kernel_1x3= np.ones((1,3), np.uint8)\n",
    "blurnel = (2, 2)\n",
    "while(True):\n",
    "    ret, img_frame = video_capture.read()\n",
    "    img_final = img_frame\n",
    "\n",
    "    # [+:]--- Use this to find the ideal value range, which changes depending on the lighting ---------------------//\n",
    "    tick= clk//clkRate + 1\n",
    "    cv2.putText(img_final, \"[:+:] CLK: \"+ str(tick), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.7, color=(200, 0, 255), thickness=2)\n",
    "    clk+= 1\n",
    "    if clk>clkLim: clk=0\n",
    "    #--------------------------------------------------------------------------------------------------------------//\n",
    "\n",
    "    # #[::+::]======================Debug================|+|+|+|\n",
    "    # clkRate= 1\n",
    "    # upper_value_bounds = np.array([255, 255, 75])\n",
    "    # # [\\\\+\\\\]===========================================|-|-|-|\n",
    "\n",
    "\n",
    "    img_hsv = cv2.cvtColor(img_frame, cv2.COLOR_BGR2HSV)\n",
    "    img_threshold = cv2.inRange(img_hsv, lower_value_bounds, upper_value_bounds)\n",
    "    img_dilate = cv2.dilate(img_threshold, kernel_1x3, iterations=4)\n",
    "    img_erode = cv2.erode(img_dilate, kernel_1x3, iterations=4)\n",
    "    img_blur = cv2.blur(img_erode, ksize= blurnel)\n",
    "\n",
    "    circles = cv2.HoughCircles(img_blur, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                  param1=houghParam1,  # edge detection parameter\n",
    "                  param2=houghParam2,  # accumulator threshold, or how circley the circles need to be to be recognized (higher=more circlely)\n",
    "                  minRadius=0,\n",
    "                  maxRadius=100)\n",
    "\n",
    "    if (type(circles)) is np.ndarray:\n",
    "        circle_radii = [x[2] for x in circles[0]] \n",
    "        circle_indexes = np.argsort(circle_radii)  \n",
    "        for i in circle_indexes[-2:]: \n",
    "            circle = circles[0][i] \n",
    "            cv2.circle(img_final, center=(int(circle[0]), int(circle[1])), radius=int(circle[2]+20), color=bgrOrange, thickness=2)  \n",
    "            text = \" -- -- \"\n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, 1, 1)  # get the text size\n",
    "            text_w, text_h = text_size  # get the text width/height\n",
    "            cv2.putText(img_final, text, org=(int(circle[0])-text_w, int(circle[1])+(text_h//2)+7), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=2, color=bgrOrange, thickness=2)\n",
    "            \n",
    "    # cv2.imshow('2 Circle_1: hsv', img_hsv)\n",
    "    cv2.imshow('3 Circle_1: threshold', img_threshold)\n",
    "    cv2.imshow(\"4 Circle1_: dilated\", img_dilate)\n",
    "    cv2.imshow(\"5 Circle_1: eroded\", img_erode)\n",
    "    cv2.imshow(\"6 Circle_1: blur\", img_blur)\n",
    "    cv2.imshow(\"7 Circle_1: final\", img_final)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __[::] Circle Detection 2__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "# [+]- Access the camera, the int parameter determines which camera you are using, may have to change in depending on what computer you run on\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "# video_capture = cv2.VideoCapture(1)\n",
    "# video_capture = cv2.VideoCapture(2)\n",
    "\n",
    "lower_value_bounds = np.array([0, 0, 150])\n",
    "# lower_value_bounds = np.array([0, 0, 165])\n",
    "# lower_value_bounds = np.array([0, 0, 180])\n",
    "upper_value_bounds = np.array([255, 255, 255])\n",
    "\n",
    "# houghParam1=40\n",
    "# houghParam2=45\n",
    "houghParam1=15\n",
    "houghParam2=30\n",
    "\n",
    "clk= 0\n",
    "clkRate= 1\n",
    "clkLim= clkRate*255\n",
    "\n",
    "\n",
    "\n",
    "kernel_sqr2 = np.ones((2,2), np.uint8)\n",
    "kernel_sqr3 = np.ones((3,3), np.uint8)\n",
    "kernel_sqr4 = np.ones((4,4), np.uint8)\n",
    "kernel_sqr5 = np.ones((5,5), np.uint8)\n",
    "kernel_sqr6 = np.ones((6,6), np.uint8)\n",
    "kernel_sqr7 = np.ones((7,7), np.uint8)\n",
    "kernel_sqr8 = np.ones((8,8), np.uint8)\n",
    "kernel_sqr9 = np.ones((9,9), np.uint8)\n",
    "kernel_sqr10 = np.ones((10,10), np.uint8)\n",
    "kernel_sqr11 = np.ones((11,11), np.uint8)\n",
    "kernel_sqr12 = np.ones((12,12), np.uint8)\n",
    "kernel_sqr13 = np.ones((13,13), np.uint8)\n",
    "kernel_sqr13 = np.ones((14,14), np.uint8)\n",
    "blurnel = (5, 5)\n",
    "kernel_3x1= np.ones((3,1), np.uint8)\n",
    "kernel_1x3= np.ones((1,3), np.uint8)\n",
    "kernel_2x1= np.ones((2,1), np.uint8)\n",
    "kernel_sqr= np.empty((0,), dtype= np.ndarray)\n",
    "erodeKernel= kernel_sqr8\n",
    "\n",
    "while(True):\n",
    "    ret, img_frame = video_capture.read()\n",
    "    img_final = img_frame\n",
    "\n",
    "    # [+:]--- Use this to find the ideal value range, which changes depending on the lighting ---------------------//\n",
    "    tick= clk//clkRate + 1\n",
    "    cv2.putText(img_final, str(tick), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.5, color= bgrOrange, thickness=2)\n",
    "    clk+= 1\n",
    "    if clk>clkLim: clk=0\n",
    "    #--------------------------------------------------------------------------------------------------------------//\n",
    "\n",
    "#[::+::]==========|============Debug===========|===========================|+|+|+|\n",
    "    #-- circl 3 starter ----\n",
    "    # clkRate= 3\n",
    "    # morphKernel= cv2.getStructuringElement(cv2.MORPH_CROSS, (2,2))  \n",
    "    # morphKernel2= cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))  \n",
    "    # blurnel2= (3, 3)\n",
    "    # morphDilate_i= 1\n",
    "    # img_blur = cv2.blur(img_morphDilate, ksize= blurnel2)\n",
    "    # img_morphDilate = cv2.dilate(img_morph,morphKernel2, iterations=morphDilate_i)\n",
    "    # morphKernel= np.ones((2,2), np.uint8)\n",
    "    # img_morph= cv2.morphologyEx(img_threshold, cv2.MORPH_GRADIENT, morphKernel)\n",
    "\n",
    "    # cv2.imshow('4.5 Circle_2: morph', img_morph)\n",
    "    # cv2.imshow('4.5 Circle_2: tmp morph->dil', img_morphDilate)\n",
    "#[\\\\+\\\\]==========|============================|===========================|-|-|-|\n",
    "\n",
    "    img_hsv = cv2.cvtColor(img_frame, cv2.COLOR_BGR2HSV)\n",
    "    img_threshold = cv2.inRange(img_hsv, lower_value_bounds, upper_value_bounds)\n",
    "    #[+:]-- erodeKernel= np.ones((7:14,7:14), np.uint8)\n",
    "    img_erode = cv2.erode(img_threshold, erodeKernel, iterations=1)\n",
    "    img_dilate = cv2.dilate(img_erode, kernel_sqr6, iterations=1)\n",
    "    img_blur = cv2.blur(img_dilate, ksize= blurnel)\n",
    "    \n",
    "\n",
    "\n",
    "    circles = cv2.HoughCircles(img_blur, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                  param1=houghParam1,  # edge detection parameter\n",
    "                  param2=houghParam2,  \n",
    "                  minRadius=0,\n",
    "                  maxRadius=100)\n",
    "\n",
    "    if (type(circles)) is np.ndarray:\n",
    "        circle_radii = [x[2] for x in circles[0]] \n",
    "        circle_indexes = np.argsort(circle_radii)  \n",
    "        for i in circle_indexes[-2:]: \n",
    "            circle = circles[0][i] \n",
    "            cv2.circle(img_final, center=(int(circle[0]), int(circle[1])), radius=int(circle[2]), color=bgrCyan, thickness=2)  \n",
    "            text = \" + \"\n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, 1, 1) \n",
    "            text_w, text_h = text_size  \n",
    "            cv2.putText(img_final, text, org=(int(circle[0]-text_w), int(circle[1])+(text_h//2)+7), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=2, color=bgrOrange, thickness=2)\n",
    "            \n",
    "    # cv2.imshow('2 Circle_1: hsv', img_hsv)\n",
    "    cv2.imshow('1 Circle_2: threshold', img_threshold)\n",
    "    cv2.imshow(\"2 Circle_2: eroded\", img_erode)\n",
    "    cv2.imshow(\"4 Circle_2_: dilated\", img_dilate)\n",
    "    cv2.imshow(\"5 Circle_2: blur\", img_blur)\n",
    "    cv2.imshow(\"6 Circle_2: final\", img_final)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  __[:+:] Circle Detection 3 - Morphological Gradient__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "# video_capture = cv2.VideoCapture(1)\n",
    "# video_capture = cv2.VideoCapture(2)\n",
    "\n",
    "clk= 0\n",
    "clkRate= 1\n",
    "clkLim= clkRate*255\n",
    "isDetected= False\n",
    "\n",
    "lower_value_bounds = np.array([0, 0, 150])\n",
    "upper_value_bounds = np.array([255, 255, 255])\n",
    "\n",
    "houghParam1=15\n",
    "houghParam2=10\n",
    "\n",
    "\n",
    "morphKernel= cv2.getStructuringElement(cv2.MORPH_CROSS, (2,2))  \n",
    "morphKernel2= cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))  \n",
    "blurnel= (3,3)\n",
    "\n",
    "while(True):\n",
    "    ret, img_frame = video_capture.read()\n",
    "    img_final = img_frame\n",
    "\n",
    "\n",
    "\n",
    "    img_hsv = cv2.cvtColor(img_frame, cv2.COLOR_BGR2HSV)\n",
    "    img_threshold = cv2.inRange(img_hsv, lower_value_bounds, upper_value_bounds)\n",
    "\n",
    "    #[+:]-- replace erode and dilate from circ 2 with morph gradient--\n",
    "    img_morphGrad = cv2.morphologyEx(img_threshold, cv2.MORPH_GRADIENT, morphKernel)\n",
    "    \n",
    "    img_dilate = cv2.dilate(img_morphGrad,morphKernel2, iterations=1)\n",
    "    img_blur = cv2.blur(img_dilate, ksize= blurnel)\n",
    "    \n",
    "\n",
    "\n",
    "    circles = cv2.HoughCircles(img_blur, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                  param1=houghParam1,  # edge detection parameter\n",
    "                  param2=houghParam2,  \n",
    "                  minRadius=0,\n",
    "                  maxRadius=100)\n",
    "    \n",
    "    \n",
    "    if (type(circles)) is np.ndarray:\n",
    "        circle_radii = [x[2] for x in circles[0]]  \n",
    "        circle_indexes = np.argsort(circle_radii)  \n",
    "        for i in circle_indexes[-2:]:  # only contour at the largest circles\n",
    "            circle = circles[0][i]  \n",
    "            cv2.circle(img_final, \n",
    "                       center=(int(circle[0]), int(circle[1])), \n",
    "                       radius=int(circle[2]), \n",
    "                       color=bgrYellow, \n",
    "                       thickness=2)  \n",
    "            text = \" (       ) \"\n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, 1, 1)  \n",
    "            text_w, text_h = text_size     \n",
    "            origX= int(circle[0])-text_w\n",
    "            origY= int(circle[1])+(text_h//2)+10                                 \n",
    "            cv2.putText(img_final, text, \n",
    "                org=(origX, origY ), \n",
    "                fontFace=cv2.FONT_HERSHEY_PLAIN, \n",
    "                fontScale=2, \n",
    "                color= bgrYellow, \n",
    "                thickness=2)\n",
    "#[::+::]=======================================|===================Heuristics==================|==================================|+|+|+|\\\\\n",
    "\n",
    "    tick= clk//clkRate + 1\n",
    "    cv2.putText(img_final, str(tick), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale= .7, color= bgrRed, thickness=2)\n",
    "    clk+= 1\n",
    "    if clk>clkLim: clk=0\n",
    "\n",
    "    if (type(circles)) is np.ndarray: \n",
    "        cirCnt= circles.shape[1]\n",
    "    cv2.putText(img_final, str(houghParam2), org=(10, 40), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.5, color= bgrRed, thickness=2)\n",
    "    cv2.putText(img_final, str(cirCnt), org=(10, 60), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.5, color= bgrRed, thickness=2)\n",
    "    if cirCnt>2:\n",
    "        houghParam2+=1\n",
    "    elif cirCnt<2:\n",
    "        houghParam2-=1\n",
    "#[\\\\+\\\\]=======================================|==========================================|==================================|-|-|-|//\n",
    "            \n",
    "    # cv2.imshow('2 Circle_1: hsv', img_hsv)\n",
    "    cv2.imshow('1 Circle_3: Threshold', img_threshold)\n",
    "    cv2.imshow(\"2 Circle_3: Thresh->Morph\", img_morphGrad)\n",
    "    cv2.imshow(\"4 Circle_3: Morph->Dilate\", img_dilate)\n",
    "    cv2.imshow(\"5 Circle_3: Dilate->Blur\", img_blur)\n",
    "    cv2.imshow(\"6 Circle_3: Final\", img_final)\n",
    "\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(houghParam2)\n",
    "        print(cirCnt)\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  __[:+:] OCR__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "camNum= 0\n",
    "video_capture = cv2.VideoCapture(camNum)\n",
    "\n",
    "clk= 0\n",
    "clkRate= 1\n",
    "clkLim= clkRate*255\n",
    "\n",
    "grayUpp= 255\n",
    "grayLow= 150\n",
    "threshUpp= 255\n",
    "threshLow= 150\n",
    "hsvLow = np.array([0, 0, 218])\n",
    "hsvUpp = np.array([157, 54, 255])\n",
    "\n",
    "dilateKernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))  \n",
    "dilate_i= 9\n",
    "\n",
    "minW= 35\n",
    "minH= 35\n",
    "maxW= 300\n",
    "maxH= 300\n",
    "\n",
    "while(True):\n",
    "    ret, frame = video_capture.read()\n",
    "    final = frame\n",
    "\n",
    "    ##[+:]=== Use this to find the ideal value range, which changes depending on the lighting ===============================\\\\\n",
    "    tick= clk//clkRate + 1\n",
    "    cv2.putText(frame, str(tick), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.5, color= bgrOrange, thickness=2)\n",
    "    clk+= 1\n",
    "    if clk>clkLim: clk=0\n",
    "    ##=======================================================================================================================//\n",
    "\n",
    "\n",
    "    #--option 1: use grayscale-----\n",
    "    img2gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    ret, grayMask = cv2.threshold(img2gray, grayLow, grayUpp, cv2.THRESH_BINARY)\n",
    "    imgFinal_gray = cv2.bitwise_and(img2gray, img2gray, mask=grayMask)\n",
    "\n",
    "    #---Option 2: use hsv-----------\n",
    "    img2hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    hsvMask = cv2.inRange(img2hsv, hsvLow, hsvUpp)\n",
    "    \n",
    "    # for black text , cv.THRESH_BINARY_INV\n",
    "    ret, new_img = cv2.threshold(imgFinal_gray, threshLow, threshUpp, cv2.THRESH_BINARY)  \n",
    "    ret, new_img_inv = cv2.threshold(imgFinal_gray, threshLow, threshUpp, cv2.THRESH_BINARY_INV)  \n",
    "\n",
    "#[::+::]==========|============Debug===========|===========================|+|+|+|\\\\\n",
    "    # clkRate= 21\n",
    "    # erodeKernel= np.ones((tick,tick), np.uint8)\n",
    "    # threshLow= 255-tick\n",
    "    # dilateKernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (tick,tick))  \n",
    "    # dilate_i= tick\n",
    "#[\\\\+\\\\]==========|============================|===========================|-|-|-|//\n",
    "\n",
    "    # dilate , more the iteration more the dilation\n",
    "    dilated = cv2.dilate(new_img_inv, dilateKernel, iterations= dilate_i)  \n",
    "\n",
    "\n",
    "    # for cv2.x.x: \n",
    "    # _, contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)  # findContours returns 3 variables for getting contours\n",
    "\n",
    "    # for cv3.x.x  comment above line and uncomment line below:\n",
    "    #image, contours, hierarchy = cv2.findContours(dilated,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # [::]-- Selection: \n",
    "    contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    for contour in contours:\n",
    "        [x, y, w, h] = cv2.boundingRect(contour)\n",
    "\n",
    "        # if w < minW and h < minH:\n",
    "        #     continue\n",
    "        # if w > maxW and h > maxH:\n",
    "        #     continue\n",
    "\n",
    "        if w<maxW and h<maxH and w>minW and h>minH:\n",
    "            # draw rectangle around contour on original image\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 255), 2)\n",
    "            cv2.putText(frame, '[' + str(w)+'x'+str(h)+']', org=(x+w//2, y+h//2), \n",
    "                        fontFace=cv2.FONT_HERSHEY_DUPLEX, \n",
    "                        fontScale=.5, color= bgrCyan, \n",
    "                        thickness=2)\n",
    "        \n",
    " \n",
    "    #cv2.imshow('0 original frame',frame)\n",
    "    cv2.imshow('1 threshold', imgFinal_gray)\n",
    "    cv2.imshow(\"1 grayMask\", grayMask)\n",
    "    # cv2.imshow(\"2  hsvMask\", hsvMask)\n",
    "    # cv2.imshow(\"3 White Text\", new_img)\n",
    "    cv2.imshow(\"4 Black Text\", new_img_inv)\n",
    "    cv2.imshow(\"5 dilated\", dilated)\n",
    "    cv2.imshow(\"6 final\", final)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectangle + Trackbars (CVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "frameWidth = 640\n",
    "frameHeight = 480\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, frameWidth)\n",
    "cap.set(4, frameHeight)\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"Trackbars\")\n",
    "cv2.resizeWindow(\"Trackbars\", 640, 240)\n",
    "cv2.createTrackbar(\"Threshold 1\", \"Trackbars\", 14, 255, nothing)\n",
    "cv2.createTrackbar(\"Threshold 2\", \"Trackbars\", 23, 255, nothing)\n",
    "cv2.createTrackbar(\"Area\", \"Trackbars\", 0, 5000, nothing)\n",
    "cv2.createTrackbar(\"maxW\", \"Trackbars\", 1000, 2000, nothing)\n",
    "cv2.createTrackbar(\"minW\", \"Trackbars\", 0, 1000, nothing)\n",
    "cv2.createTrackbar(\"maxH\", \"Trackbars\", 1000, 2000, nothing)\n",
    "cv2.createTrackbar(\"minH\", \"Trackbars\", 0, 1000, nothing)\n",
    "\n",
    "def stackImages(scale, imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width =imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range (0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape[:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0,0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y] = cv2.cvtColor(imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank] *rows\n",
    "        for x in range (0,rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0,rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0,0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None, scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor = np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    "                    \n",
    "def getContours(img, imgContour):\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    #cv2.drawContours(imgContour, contours, -1, (255, 0, 255), 7)\n",
    "    \n",
    "    for cnt in contours:\n",
    "        \"\"\"\n",
    "        area = cv2.contourArea(cnt)\n",
    "        maxArea = cv2.getTrackbarPos(\"Area\", \"Trackbars\")\n",
    "        if area < maxArea:\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255, 0, 255), 7)\n",
    "            peri = cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "            #print(approx)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            cv2.rectangle(imgContour, (x, y), (x + w, y + h), (0, 255, 0), 5)\n",
    "\n",
    "            #cv2.putText(imgContour, \"Points: \" + str(len(approx)), (x + w + 20, y + 20), cv2.FONT_HERSHEY_COMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(imgContour, \"Area: \" + str(int(area)), (x + w + 20, y + 45), cv2.FONT_HERSHEY_COMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \"\"\"\n",
    "        \n",
    "        peri = cv2.arcLength(cnt, True)\n",
    "        area = cv2.contourArea(cnt)\n",
    "        approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "        x, y, w, h = cv2.boundingRect(approx)\n",
    "        maxW = cv2.getTrackbarPos(\"maxW\", \"Trackbars\")\n",
    "        maxH = cv2.getTrackbarPos(\"maxH\", \"Trackbars\")\n",
    "        minW = cv2.getTrackbarPos(\"minW\", \"Trackbars\")\n",
    "        minH = cv2.getTrackbarPos(\"minH\", \"Trackbars\")\n",
    "        if w < maxW and h < maxH and w > minW and h > minH:\n",
    "            cv2.rectangle(imgContour, (x, y), (x + w, y + h), (0, 255, 0), 5)\n",
    "            #cv2.putText(imgContour, \"Points: \" + str(len(approx)), (x + w + 20, y + 20), cv2.FONT_HERSHEY_COMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(imgContour, \"Area: \" + str(int(area)), (x + w + 20, y + 45), cv2.FONT_HERSHEY_COMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "\n",
    "    \n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgContour = img.copy()\n",
    "\n",
    "    imgBlur = cv2.GaussianBlur(img, (7,7), 1)\n",
    "    imgGray = cv2.cvtColor(imgBlur, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    threshold1 = cv2.getTrackbarPos(\"Threshold 1\", \"Trackbars\")\n",
    "    #threshold1 = 14\n",
    "    threshold2 = cv2.getTrackbarPos(\"Threshold 2\", \"Trackbars\")\n",
    "    #threshold2 = 23\n",
    "    imgCanny = cv2.Canny(imgGray, threshold1, threshold2)\n",
    "    #imgCanny = cv2.Canny(imgGray, 143, 102)\n",
    "    kernel = np.ones((5,5))\n",
    "    imgDil = cv2.dilate(imgCanny, kernel, iterations = 1)\n",
    "\n",
    "    getContours(imgDil, imgContour)\n",
    "\n",
    "    imgStack = stackImages(0.8, ([img, imgGray, imgCanny], [imgDil, imgContour, imgContour]))\n",
    "\n",
    "    cv2.imshow(\"Result\", imgStack)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "while True:\n",
    "    ret, capturing = cap.read()\n",
    "    hsv = cv2.cvtColor(capturing, cv2.COLOR_BGR2HSV)\n",
    "    blur = cv2.GaussianBlur(hsv, (7, 7), 0)\n",
    "    edge = cv2.Canny(blur, 100, 100)\n",
    "\n",
    "    # Make it in a way that only shows the shapes and blacks out everything else\n",
    "    ret, thresh1 = cv2.threshold(edge, 220, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow('Original', capturing)\n",
    "    cv2.imshow('Edges', thresh1)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  __[:+:] Tasks__\n",
    "- [x] Gate Task Circle Detection 1\n",
    "- [x] Gate Task Circle Detection 2\n",
    "- [ ] OCR\n",
    "- [ ] Morphological Gradient; gradient = cv.morphologyEx(img, cv.MORPH_GRADIENT, kernel)\n",
    "- [ ] Trimmed Mean\n",
    "- [ ] Box Detection\n",
    "- [ ] Ensemble of Algorithms\n",
    "    - [ ] Helper Functions\n",
    "    - [ ] Polling System\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10065f837bc8873f5387f5268b450066d881a20043fa6c000aa3f801fbe31849"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
