{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __[:+:] -- DragonVision Prototype-- [:+:]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [+] Libraries that are commented out are only for ROS\n",
    "#import rospy\n",
    "#from std_msgs.msg import Float64\n",
    "#from sensor_msgs.msg import Image\n",
    "#from cv_bridge import CvBridge, CvBridgeError\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "\n",
    "#[+------:\n",
    "import sys\n",
    "\n",
    "bgrRed= (0, 0, 255)\n",
    "bgrGreen= (0, 255, 0)\n",
    "bgrBlue= (255, 0, 0)\n",
    "bgrCyan= (200, 200, 50)\n",
    "bgrMagenta= (150, 40, 200)\n",
    "bgrYellow= (75, 200, 255)\n",
    "bgrOrange= (100, 100, 255)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [+]-- Helper Fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackImages(scale, imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width =imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range (0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape[:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0,0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y] = cv2.cvtColor(imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank] *rows\n",
    "        for x in range (0,rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0,rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0,0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None, scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor = np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __[::] Gate (2022)__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "# [+]- Access the camera, the int parameter determines which camera you are using, may have to change in depending on what computer you run on\n",
    "camNum= 2 #0,1,or 2\n",
    "video_capture = cv2.VideoCapture(camNum)\n",
    "\n",
    "\n",
    "#[+]- Each iteration of this loop processes a frame that is captured by the camera by applying a series of filters. Each filter is in intermediate step, the final image is the one which we annotate and extract information from. \n",
    "while(True):\n",
    "    # Capture the frames\n",
    "    ret, frame = video_capture.read()\n",
    "    final = frame\n",
    "\n",
    "    # change from bgr values to hsv values\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # color bounds of color to be filtered out [+] correction: colors to be NOT filtered out\n",
    "    # lower_color_bounds = np.array([0, 200, 0])\n",
    "    # upper_color_bounds = np.array([255, 255, 255])\n",
    "    lower_color_bounds = np.array([0, 100, 20])\n",
    "    upper_color_bounds = np.array([30, 255, 255])\n",
    "\n",
    "\n",
    "    # [+]- Filter 1: threshold shows in black the pixels being filtered out [+: show only the colors that are between the two bounds)\n",
    "    threshold = cv2.inRange(hsv, lower_color_bounds, upper_color_bounds)\n",
    "\n",
    "    #[+]- Filter 2:  erode to remove noise\n",
    "    kernel = np.ones((10, 10), np.uint8)\n",
    "    erode = cv2.erode(threshold, kernel)\n",
    "\n",
    "    # get the contours, Each individual contour is a Numpy array of (x,y) coordinates of boundary points of the object\n",
    "    contours = cv2.findContours(erode, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0]\n",
    "\n",
    "    # create bounding boxes, creates an array of contour areas so that we can know which is th ebiggest\n",
    "    contour_areas = [cv2.contourArea(x) for x in contours]  \n",
    "    \n",
    "    # get the areas of each contour, returns a list of indeces for contour areas array\n",
    "    contour_indexes = np.argsort(contour_areas)  \n",
    "    \n",
    "    # sort the indexes of the largest areas\n",
    "    for i in contour_indexes[-2:]:  # only look at the two largest contours\n",
    "        (x,y,w,h) = cv2.boundingRect(contours[i])  # get the location/dimensions of a bounding box for the contour: x,y=coordinates, w,h=dims\n",
    "        cv2.rectangle(final, pt1=(x,y), pt2=(x+w,y+h), color=(255,0,0), thickness=5)  # draw the bounding box on the image\n",
    "\n",
    "        # for visibility, we will place a background fill on the contour label\n",
    "        text = \"gatepost\"\n",
    "        text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, 1, 1)\n",
    "        text_w, text_h = text_size\n",
    "        cv2.rectangle(final, pt1=(x, y), pt2=(x + text_w, y - 2*text_h), color=(255, 0, 0), thickness=-1)\n",
    "        cv2.putText(final, \"gatepost\", org=(x, y-5), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=1, color=(255, 255, 255), thickness=1)\n",
    "\n",
    "    # [+]- Show each filter that is applied to the frame. Each filter is shown in a separate window\n",
    "    # cv2.imshow('1 Gate: original frame',frame)\n",
    "    cv2.imshow('2 Gate: threshold', threshold)\n",
    "    cv2.imshow(\"3 Gate: eroded\", erode)\n",
    "    cv2.imshow(\"4 Gate: final\", final)\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __[::] Buoy (2022)__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "# [+]- Access the camera, the int parameter determines which camera you are using, may have to change in depending on what computer you run on\n",
    "video_capture = cv2.VideoCapture(1)\n",
    "# video_capture = cv2.VideoCapture(1)\n",
    "# video_capture = cv2.VideoCapture(2)\n",
    "\n",
    "# # color bounds of color to be [NOT] filtered out, by default it filters out light colors so that it can identif \n",
    "lower_value_bounds = np.array([0, 0, 0])\n",
    "upper_value_bounds = np.array([255, 255, 45])\n",
    "\n",
    "\n",
    "#[+:]-- -------------------------------------------------//\n",
    "lower_value_bounds2 = np.array([0, 0, 0])\n",
    "upper_value_bounds2 = np.array([255, 255, 80])\n",
    "clk= 0\n",
    "clkRate= 9\n",
    "clkLim= clkRate*255\n",
    "#-------------------------------------------------------//\n",
    "\n",
    "dilateKernel = np.ones((5, 5), np.uint8)\n",
    "erodeKernel = np.ones((10, 10), np.uint8)\n",
    "erodeKernel2= np.ones((6, 6), np.uint8)\n",
    "blurnel = (5, 5)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    # Capture the frames\n",
    "    ret, img_frame = video_capture.read()\n",
    "    img_final = img_frame\n",
    "\n",
    "    # change from bgr values to hsv values\n",
    "    img_hsv = cv2.cvtColor(img_frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "\n",
    "    # threshold shows in black the pixels being filtered out\n",
    "    img_threshold = cv2.inRange(img_hsv, lower_value_bounds, upper_value_bounds)\n",
    "\n",
    "    #  [+:] -- Use this to find the ideal value range, which changes depending on the lighting ----------//\n",
    "    tick= clk//clkRate\n",
    "    # img_threshold = cv2.inRange(img_hsv, np.array([0, 0, 0]), np.array([255, 255, tick]))\n",
    "    # cv2.putText(img_final, \"[:+:] CLK: \"+ str(tick), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.7, color=(200, 150, 0), thickness=2)\n",
    "    # clk+= 1\n",
    "    # if clk>clkLim: clk=0\n",
    "    #-----------------------------------------------------------------------------------------------------//\n",
    "\n",
    "    # dilate to combine contours\n",
    "    img_dilate = cv2.dilate(img_threshold, dilateKernel, iterations=3)\n",
    "\n",
    "    # erode to remove noise\n",
    "    img_erode = cv2.erode(img_dilate, erodeKernel, iterations=2)\n",
    "\n",
    "    # blur to smooth edges so circle detection is easier\n",
    "    img_blur = cv2.blur(img_erode, ksize= blurnel)\n",
    "\n",
    "    # detect circles\n",
    "    circles = cv2.HoughCircles(img_blur, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                  param1=30,  # edge detection parameter\n",
    "                  param2=30,  # accumulator threshold, or how circley the circles need to be to be recognized (higher=more circlely)\n",
    "                  minRadius=0,\n",
    "                  maxRadius=100)\n",
    "\n",
    "    # if a circle is identified\n",
    "    if (type(circles)) is np.ndarray:\n",
    "        # draw the circles\n",
    "        circle_radii = [x[2] for x in circles[0]]  # get the radii of each contour\n",
    "        circle_indexes = np.argsort(circle_radii)  # sort by largest radius\n",
    "        for i in circle_indexes[-2:]:  # only contour at the largest circles\n",
    "            circle = circles[0][i]  # get the largest circle\n",
    "            cv2.circle(img_final, center=(int(circle[0]), int(circle[1])), radius=int(circle[2]), color=(100, 0, 255), thickness=2)  # draw the circle on the image\n",
    "            # make the text centered\n",
    "            # text = \"police buoy\"\n",
    "            text = \" --  -- \"\n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, 1, 1)  # get the text size\n",
    "            text_w, text_h = text_size  # get the text width/height\n",
    "            cv2.putText(img_final, text, org=(int(circle[0])-text_w, int(circle[1])+(text_h//2)+8), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=2, color=(100, 0, 255), thickness=2)\n",
    "\n",
    "\n",
    "    #[:+:]===============================================================================================================================================[:+:]\n",
    "    clkRate= 1\n",
    "    #[+]-------- ----------------------------------------------------------------------------//\n",
    "    img_threshold2 = cv2.inRange(img_hsv, np.array([0, 0, 0]), np.array([255, 255, 80]))\n",
    "    cv2.putText(img_final, (\"[:+:] CLK: \"+ str(tick)), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.7, color=(100, 255, 100), thickness=2)\n",
    "    clk+= 1\n",
    "    if clk>clkLim: clk=0\n",
    "    #----------------------------------------------------------------------------------------//\n",
    "\n",
    "    img_erode2 = cv2.erode(img_threshold2, erodeKernel2, iterations=1)\n",
    "\n",
    "    dilateKernel2 = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    img_dilate2 = cv2.dilate(img_erode2, dilateKernel2, iterations=3)\n",
    "\n",
    "    img_blur2 = cv2.blur(img_erode2, ksize=blurnel)\n",
    "\n",
    "    circles2 = cv2.HoughCircles(img_blur2, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                  param1=30,  # edge detection parameter\n",
    "                  param2=30,  # accumulator threshold, or how circley the circles need to be to be recognized (higher=more circlely)\n",
    "                  minRadius=0,\n",
    "                  maxRadius=100)\n",
    "\n",
    "#[+:] --- Circle Array # 2 -----------------------------------------\n",
    "    if (type(circles2)) is np.ndarray:\n",
    "        circle_radii = [x[2] for x in circles2[0]]  \n",
    "        circle_indexes = np.argsort(circle_radii)  \n",
    "        for i in circle_indexes[-2:]:  \n",
    "            circle = circles2[0][i] \n",
    "            cv2.circle(img_final, center=(int(circle[0]), int(circle[1])), radius=int(circle[2])+25, color=(200, 150, 0), thickness=2) \n",
    "            text = \"[:+:]\"\n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_DUPLEX, 1, 1)  \n",
    "            text_w, text_h = text_size  \n",
    "            cv2.putText(img_final, text, org=(int(circle[0])-text_w, int(circle[1])+text_h), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=2, color=(200, 150, 0), thickness=2)\n",
    "#[:\\:]===============================================================================================================================================[:\\:]\n",
    "\n",
    "\n",
    "\n",
    "    # [+] show frames\n",
    "    # cv2.imshow('1 original frame', img_frame)\n",
    "    # cv2.imshow('2 Buoy: hsv', img_hsv)\n",
    "    # cv2.imshow('3 Buoy: threshold', img_threshold)\n",
    "    # cv2.imshow(\"4 Buoy: dilated\", img_dilate)\n",
    "    # cv2.imshow(\"5 Buoy: eroded\", img_erode)\n",
    "    # cv2.imshow(\"6 Buoy: blur\", img_blur)\n",
    "    # cv2.imshow(\"7 Buoy: final\", img_final)\n",
    "\n",
    "    #[+: ------------------------------------------------- ::\n",
    "    # cv2.imshow('1 original frame2', img_frame)\n",
    "    # cv2.imshow('2 Buoy: hsv2', img_hsv)\n",
    "    cv2.imshow('3 Buoy: threshold2', img_threshold2)\n",
    "    cv2.imshow(\"4 Buoy: dilated2\", img_dilate2)\n",
    "    cv2.imshow(\"5 Buoy: eroded2\", img_erode2)\n",
    "    cv2.imshow(\"6 Buoy: blur2\", img_blur2)\n",
    "    #::-----------------------------------------------------:+]\n",
    "    cv2.imshow(\"7 Buoy: final2\", img_final)\n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __[::] Circle Detection__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\bld\\libopencv_1661643119770\\work\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pc\\OneDrive\\CSEC_Robosub\\richardCode\\Repo\\DragonVision_2023.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/OneDrive/CSEC_Robosub/richardCode/Repo/DragonVision_2023.ipynb#X10sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mif\u001b[39;00m clk\u001b[39m>\u001b[39mclkLim: clk\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/OneDrive/CSEC_Robosub/richardCode/Repo/DragonVision_2023.ipynb#X10sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m#--------------------------------------------------------------------------------------------------------------//\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/OneDrive/CSEC_Robosub/richardCode/Repo/DragonVision_2023.ipynb#X10sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/OneDrive/CSEC_Robosub/richardCode/Repo/DragonVision_2023.ipynb#X10sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# #[::+::]======================Debug================|+|+|+|\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/OneDrive/CSEC_Robosub/richardCode/Repo/DragonVision_2023.ipynb#X10sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# clkRate= 1\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/OneDrive/CSEC_Robosub/richardCode/Repo/DragonVision_2023.ipynb#X10sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# upper_value_bounds = np.array([255, 255, 75])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/OneDrive/CSEC_Robosub/richardCode/Repo/DragonVision_2023.ipynb#X10sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# # [\\\\+\\\\]===========================================|-|-|-|\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pc/OneDrive/CSEC_Robosub/richardCode/Repo/DragonVision_2023.ipynb#X10sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m img_hsv \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(img_frame, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2HSV)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/OneDrive/CSEC_Robosub/richardCode/Repo/DragonVision_2023.ipynb#X10sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m img_threshold \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39minRange(img_hsv, lower_value_bounds, upper_value_bounds)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/OneDrive/CSEC_Robosub/richardCode/Repo/DragonVision_2023.ipynb#X10sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m img_dilate \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mdilate(img_threshold, kernel_1x3, iterations\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\bld\\libopencv_1661643119770\\work\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "# [+]- Access the camera, the int parameter determines which camera you are using, may have to change in depending on what computer you run on\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "# video_capture = cv2.VideoCapture(1)\n",
    "# video_capture = cv2.VideoCapture(2)\n",
    "\n",
    "lower_value_bounds = np.array([0, 0, 0])\n",
    "upper_value_bounds = np.array([255, 255, 75])\n",
    "\n",
    "houghParam1=40\n",
    "houghParam2=45\n",
    "# houghParam1=15\n",
    "# houghParam2=30\n",
    "\n",
    "#[+:]-- -------------------------------------------------//\n",
    "clk= 0\n",
    "clkRate= 1\n",
    "clkLim= clkRate*255\n",
    "#-------------------------------------------------------//\n",
    "\n",
    "\n",
    "kernel_sqr = np.ones((1,1), np.uint8)\n",
    "kernel_3x1= np.ones((3,1), np.uint8)\n",
    "kernel_1x3= np.ones((1,3), np.uint8)\n",
    "blurnel = (2, 2)\n",
    "while(True):\n",
    "    ret, img_frame = video_capture.read()\n",
    "    img_final = img_frame\n",
    "\n",
    "    # [+:]--- Use this to find the ideal value range, which changes depending on the lighting ---------------------//\n",
    "    tick= clk//clkRate + 1\n",
    "    cv2.putText(img_final, \"[:+:] CLK: \"+ str(tick), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.7, color=(200, 0, 255), thickness=2)\n",
    "    clk+= 1\n",
    "    if clk>clkLim: clk=0\n",
    "    #--------------------------------------------------------------------------------------------------------------//\n",
    "\n",
    "    # #[::+::]======================Debug================|+|+|+|\n",
    "    # clkRate= 1\n",
    "    # upper_value_bounds = np.array([255, 255, 75])\n",
    "    # # [\\\\+\\\\]===========================================|-|-|-|\n",
    "\n",
    "\n",
    "    img_hsv = cv2.cvtColor(img_frame, cv2.COLOR_BGR2HSV)\n",
    "    img_threshold = cv2.inRange(img_hsv, lower_value_bounds, upper_value_bounds)\n",
    "    img_dilate = cv2.dilate(img_threshold, kernel_1x3, iterations=4)\n",
    "    img_erode = cv2.erode(img_dilate, kernel_1x3, iterations=4)\n",
    "    img_blur = cv2.blur(img_erode, ksize= blurnel)\n",
    "\n",
    "    circles = cv2.HoughCircles(img_blur, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                  param1=houghParam1,  # edge detection parameter\n",
    "                  param2=houghParam2,  # accumulator threshold, or how circley the circles need to be to be recognized (higher=more circlely)\n",
    "                  minRadius=0,\n",
    "                  maxRadius=100)\n",
    "\n",
    "    if (type(circles)) is np.ndarray:\n",
    "        circle_radii = [x[2] for x in circles[0]] \n",
    "        circle_indexes = np.argsort(circle_radii)  \n",
    "        for i in circle_indexes[-2:]: \n",
    "            circle = circles[0][i] \n",
    "            cv2.circle(img_final, center=(int(circle[0]), int(circle[1])), radius=int(circle[2]+20), color=bgrOrange, thickness=2)  \n",
    "            text = \" -- -- \"\n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, 1, 1)  # get the text size\n",
    "            text_w, text_h = text_size  # get the text width/height\n",
    "            cv2.putText(img_final, text, org=(int(circle[0])-text_w, int(circle[1])+(text_h//2)+7), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=2, color=bgrOrange, thickness=2)\n",
    "            \n",
    "    # cv2.imshow('2 Circle_1: hsv', img_hsv)\n",
    "    cv2.imshow('3 Circle_1: threshold', img_threshold)\n",
    "    cv2.imshow(\"4 Circle1_: dilated\", img_dilate)\n",
    "    cv2.imshow(\"5 Circle_1: eroded\", img_erode)\n",
    "    cv2.imshow(\"6 Circle_1: blur\", img_blur)\n",
    "    cv2.imshow(\"7 Circle_1: final\", img_final)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __[::] Circle Detection 2__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pc\\OneDrive\\CSEC_Robosub\\richardCode\\Repo\\DragonVision_2023.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/OneDrive/CSEC_Robosub/richardCode/Repo/DragonVision_2023.ipynb#X12sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m \u001b[39m# [+:]--- Use this to find the ideal value range, which changes depending on the lighting ---------------------//\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/OneDrive/CSEC_Robosub/richardCode/Repo/DragonVision_2023.ipynb#X12sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m tick\u001b[39m=\u001b[39m clk\u001b[39m/\u001b[39m\u001b[39m/\u001b[39mclkRate \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pc/OneDrive/CSEC_Robosub/richardCode/Repo/DragonVision_2023.ipynb#X12sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m cv2\u001b[39m.\u001b[39mputText(img_final, \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39;49m(circles)), org\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m20\u001b[39m), fontFace\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mFONT_HERSHEY_DUPLEX, fontScale\u001b[39m=\u001b[39m\u001b[39m.5\u001b[39m, color\u001b[39m=\u001b[39m bgrOrange, thickness\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/OneDrive/CSEC_Robosub/richardCode/Repo/DragonVision_2023.ipynb#X12sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m clk\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/OneDrive/CSEC_Robosub/richardCode/Repo/DragonVision_2023.ipynb#X12sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39mif\u001b[39;00m clk\u001b[39m>\u001b[39mclkLim: clk\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "# [+]- Access the camera, the int parameter determines which camera you are using, may have to change in depending on what computer you run on\n",
    "video_capture = cv2.VideoCapture(2)\n",
    "# video_capture = cv2.VideoCapture(1)\n",
    "# video_capture = cv2.VideoCapture(2)\n",
    "\n",
    "lower_value_bounds = np.array([0, 0, 150])\n",
    "# lower_value_bounds = np.array([0, 0, 165])\n",
    "# lower_value_bounds = np.array([0, 0, 180])\n",
    "upper_value_bounds = np.array([255, 255, 255])\n",
    "\n",
    "# houghParam1=40\n",
    "# houghParam2=45\n",
    "houghParam1=15\n",
    "houghParam2=30\n",
    "\n",
    "clk= 0\n",
    "clkRate= 1\n",
    "clkLim= clkRate*255\n",
    "\n",
    "\n",
    "\n",
    "kernel_sqr2 = np.ones((2,2), np.uint8)\n",
    "kernel_sqr3 = np.ones((3,3), np.uint8)\n",
    "kernel_sqr4 = np.ones((4,4), np.uint8)\n",
    "kernel_sqr5 = np.ones((5,5), np.uint8)\n",
    "kernel_sqr6 = np.ones((6,6), np.uint8)\n",
    "kernel_sqr7 = np.ones((7,7), np.uint8)\n",
    "kernel_sqr8 = np.ones((8,8), np.uint8)\n",
    "kernel_sqr9 = np.ones((9,9), np.uint8)\n",
    "kernel_sqr10 = np.ones((10,10), np.uint8)\n",
    "kernel_sqr11 = np.ones((11,11), np.uint8)\n",
    "kernel_sqr12 = np.ones((12,12), np.uint8)\n",
    "kernel_sqr13 = np.ones((13,13), np.uint8)\n",
    "kernel_sqr13 = np.ones((14,14), np.uint8)\n",
    "blurnel = (5, 5)\n",
    "kernel_3x1= np.ones((3,1), np.uint8)\n",
    "kernel_1x3= np.ones((1,3), np.uint8)\n",
    "kernel_2x1= np.ones((2,1), np.uint8)\n",
    "kernel_sqr= np.empty((0,), dtype= np.ndarray)\n",
    "erodeKernel= kernel_sqr8\n",
    "\n",
    "while(True):\n",
    "    ret, img_frame = video_capture.read()\n",
    "    img_final = img_frame\n",
    "\n",
    "    # # [+:]--- Use this to find the ideal value range, which changes depending on the lighting ---------------------//\n",
    "    # tick= clk//clkRate + 1\n",
    "    # cv2.putText(img_final, str(tick), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.5, color= bgrOrange, thickness=2)\n",
    "    # clk+= 1\n",
    "    # if clk>clkLim: clk=0\n",
    "    # #--------------------------------------------------------------------------------------------------------------//\n",
    "\n",
    "#[::+::]==========|============Debug===========|===========================|+|+|+|\n",
    "    #-- circl 3 starter ----\n",
    "    # clkRate= 3\n",
    "    # morphKernel= cv2.getStructuringElement(cv2.MORPH_CROSS, (2,2))  \n",
    "    # morphKernel2= cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))  \n",
    "    # blurnel2= (3, 3)\n",
    "    # morphDilate_i= 1\n",
    "    # img_blur = cv2.blur(img_morphDilate, ksize= blurnel2)\n",
    "    # img_morphDilate = cv2.dilate(img_morph,morphKernel2, iterations=morphDilate_i)\n",
    "    # morphKernel= np.ones((2,2), np.uint8)\n",
    "    # img_morph= cv2.morphologyEx(img_threshold, cv2.MORPH_GRADIENT, morphKernel)\n",
    "\n",
    "    # cv2.imshow('4.5 Circle_2: morph', img_morph)\n",
    "    # cv2.imshow('4.5 Circle_2: tmp morph->dil', img_morphDilate)\n",
    "#[\\\\+\\\\]==========|============================|===========================|-|-|-|\n",
    "\n",
    "    img_hsv = cv2.cvtColor(img_frame, cv2.COLOR_BGR2HSV)\n",
    "    img_threshold = cv2.inRange(img_hsv, lower_value_bounds, upper_value_bounds)\n",
    "    #[+:]-- erodeKernel= np.ones((7:14,7:14), np.uint8)\n",
    "    img_erode = cv2.erode(img_threshold, erodeKernel, iterations=1)\n",
    "    img_dilate = cv2.dilate(img_erode, kernel_sqr6, iterations=1)\n",
    "    img_blur = cv2.blur(img_dilate, ksize= blurnel)\n",
    "    \n",
    "\n",
    "\n",
    "    circles = cv2.HoughCircles(img_blur, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                  param1=houghParam1,  # edge detection parameter\n",
    "                  param2=houghParam2,  \n",
    "                  minRadius=0,\n",
    "                  maxRadius=100)\n",
    "    \n",
    "\n",
    "    # [+:]--- Use this to find the ideal value range, which changes depending on the lighting ---------------------//\n",
    "    tick= clk//clkRate + 1\n",
    "    cv2.putText(img_final, str(len(circles)), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.5, color= bgrOrange, thickness=2)\n",
    "    clk+= 1\n",
    "    if clk>clkLim: clk=0\n",
    "    #--------------------------------------------------------------------------------------------------------------//\n",
    "\n",
    "    if (type(circles)) is np.ndarray:\n",
    "        circle_radii = [x[2] for x in circles[0]] \n",
    "        circle_indexes = np.argsort(circle_radii)  \n",
    "        for i in circle_indexes[-2:]: \n",
    "            circle = circles[0][i] \n",
    "            cv2.circle(img_final, center=(int(circle[0]), int(circle[1])), radius=int(circle[2]), color=bgrCyan, thickness=2)  \n",
    "            text = \" + \"\n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, 1, 1) \n",
    "            text_w, text_h = text_size  \n",
    "            cv2.putText(img_final, \n",
    "                        text, \n",
    "                        org=(int(circle[0]-text_w), \n",
    "                                              int(circle[1])+(text_h//2)+7), \n",
    "                                              fontFace=cv2.FONT_HERSHEY_PLAIN, \n",
    "                                              fontScale=2, \n",
    "                                              color=bgrOrange, \n",
    "                                              thickness=2)\n",
    "            \n",
    "    # cv2.imshow('2 Circle_1: hsv', img_hsv)\n",
    "    cv2.imshow('1 Circle_2: threshold', img_threshold)\n",
    "    cv2.imshow(\"2 Circle_2: eroded\", img_erode)\n",
    "    cv2.imshow(\"4 Circle_2_: dilated\", img_dilate)\n",
    "    cv2.imshow(\"5 Circle_2: blur\", img_blur)\n",
    "    cv2.imshow(\"6 Circle_2: final\", img_final)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  __[:+:] Circle Detection 3 - Morphological Gradient__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "video_capture = cv2.VideoCapture(2)\n",
    "# video_capture = cv2.VideoCapture(1)\n",
    "# video_capture = cv2.VideoCapture(2)\n",
    "\n",
    "clk= 0\n",
    "clkRate= 1\n",
    "clkLim= clkRate*255\n",
    "isDetected= False\n",
    "\n",
    "lower_value_bounds = np.array([0, 0, 150])\n",
    "upper_value_bounds = np.array([255, 255, 255])\n",
    "\n",
    "houghParam1=15\n",
    "houghParam2=10\n",
    "\n",
    "\n",
    "morphKernel= cv2.getStructuringElement(cv2.MORPH_CROSS, (2,2))  \n",
    "morphKernel2= cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))  \n",
    "blurnel= (3,3)\n",
    "\n",
    "while(True):\n",
    "    ret, img_frame = video_capture.read()\n",
    "    img_final = img_frame\n",
    "\n",
    "\n",
    "\n",
    "    img_hsv = cv2.cvtColor(img_frame, cv2.COLOR_BGR2HSV)\n",
    "    img_threshold = cv2.inRange(img_hsv, lower_value_bounds, upper_value_bounds)\n",
    "\n",
    "    #[+:]-- replace erode and dilate from circ 2 with morph gradient--\n",
    "    img_morphGrad = cv2.morphologyEx(img_threshold, cv2.MORPH_GRADIENT, morphKernel)\n",
    "    \n",
    "    img_dilate = cv2.dilate(img_morphGrad,morphKernel2, iterations=1)\n",
    "    img_blur = cv2.blur(img_dilate, ksize= blurnel)\n",
    "    \n",
    "\n",
    "\n",
    "    circles = cv2.HoughCircles(img_blur, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                  param1=houghParam1,  # edge detection parameter\n",
    "                  param2=houghParam2,  \n",
    "                  minRadius=0,\n",
    "                  maxRadius=100)\n",
    "    \n",
    "    \n",
    "    if (type(circles)) is np.ndarray:\n",
    "        circle_radii = [x[2] for x in circles[0]]  \n",
    "        circle_indexes = np.argsort(circle_radii)  \n",
    "        for i in circle_indexes[-2:]:  # only contour at the largest circles\n",
    "            circle = circles[0][i]  \n",
    "            cv2.circle(img_final, \n",
    "                       center=(int(circle[0]), int(circle[1])), \n",
    "                       radius=int(circle[2]), \n",
    "                       color=bgrYellow, \n",
    "                       thickness=2)  \n",
    "            text = \" (       ) \"\n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, 1, 1)  \n",
    "            text_w, text_h = text_size     \n",
    "            origX= int(circle[0])-text_w\n",
    "            origY= int(circle[1])+(text_h//2)+10                                 \n",
    "            cv2.putText(img_final, text, \n",
    "                org=(origX, origY ), \n",
    "                fontFace=cv2.FONT_HERSHEY_PLAIN, \n",
    "                fontScale=2, \n",
    "                color= bgrYellow, \n",
    "                thickness=2)\n",
    "#[::+::]=======================================|===================Heuristics==================|==================================|+|+|+|\\\\\n",
    "\n",
    "    tick= clk//clkRate + 1\n",
    "    cv2.putText(img_final, str(tick), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale= .7, color= bgrRed, thickness=2)\n",
    "    clk+= 1\n",
    "    if clk>clkLim: clk=0\n",
    "\n",
    "    if (type(circles)) is np.ndarray: \n",
    "        cirCnt= circles.shape[1]\n",
    "    cv2.putText(img_final, 'houghParam2 '+str(houghParam2), org=(10, 40), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.5, color= bgrRed, thickness=2)\n",
    "    cv2.putText(img_final, 'cirCnt '+str(cirCnt), org=(10, 60), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.5, color= bgrRed, thickness=2)\n",
    "    if cirCnt>2:\n",
    "        houghParam2+=1\n",
    "    elif cirCnt<2:\n",
    "        houghParam2-=1\n",
    "#[\\\\+\\\\]=======================================|==========================================|==================================|-|-|-|//\n",
    "            \n",
    "    # cv2.imshow('2 Circle_1: hsv', img_hsv)\n",
    "    # cv2.imshow('1 Circle_3: Threshold', img_threshold)\n",
    "    # cv2.imshow(\"2 Circle_3: Thresh->Morph\", img_morphGrad)\n",
    "    # cv2.imshow(\"4 Circle_3: Morph->Dilate\", img_dilate)\n",
    "    # cv2.imshow(\"5 Circle_3: Dilate->Blur\", img_blur)\n",
    "    # cv2.imshow(\"6 Circle_3: Final\", img_final)\n",
    "\n",
    "    imgStack = stackImages(0.5, ([img_hsv, img_threshold, img_morphGrad], [img_dilate, img_blur, img_final]))\n",
    "    cv2.imshow(\"Result\", imgStack)\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(houghParam2)\n",
    "        print(cirCnt)\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  __[:+:] OCR__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5000/61980179.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mcamNum\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mvideo_capture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcamNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mclk\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "camNum= 0\n",
    "video_capture = cv2.VideoCapture(camNum)\n",
    "\n",
    "clk= 0\n",
    "clkRate= 1\n",
    "clkLim= clkRate*255\n",
    "\n",
    "grayUpp= 255\n",
    "grayLow= 150\n",
    "threshUpp= 255\n",
    "threshLow= 150\n",
    "hsvLow = np.array([0, 0, 218])\n",
    "hsvUpp = np.array([157, 54, 255])\n",
    "\n",
    "dilateKernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))  \n",
    "dilate_i= 9\n",
    "\n",
    "minW= 35\n",
    "minH= 35\n",
    "maxW= 300\n",
    "maxH= 300\n",
    "\n",
    "while(True):\n",
    "    ret, frame = video_capture.read()\n",
    "    final = frame\n",
    "\n",
    "    ##[+:]=== Use this to find the ideal value range, which changes depending on the lighting ===============================\\\\\n",
    "    tick= clk//clkRate + 1\n",
    "    cv2.putText(frame, str(tick), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.5, color= bgrOrange, thickness=2)\n",
    "    clk+= 1\n",
    "    if clk>clkLim: clk=0\n",
    "    ##=======================================================================================================================//\n",
    "\n",
    "\n",
    "    #--option 1: use grayscale-----\n",
    "    img2gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    ret, grayMask = cv2.threshold(img2gray, grayLow, grayUpp, cv2.THRESH_BINARY)\n",
    "    imgFinal_gray = cv2.bitwise_and(img2gray, img2gray, mask=grayMask)\n",
    "\n",
    "    #---Option 2: use hsv-----------\n",
    "    img2hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    hsvMask = cv2.inRange(img2hsv, hsvLow, hsvUpp)\n",
    "    \n",
    "    # for black text , cv.THRESH_BINARY_INV\n",
    "    ret, new_img = cv2.threshold(imgFinal_gray, threshLow, threshUpp, cv2.THRESH_BINARY)  \n",
    "    ret, new_img_inv = cv2.threshold(imgFinal_gray, threshLow, threshUpp, cv2.THRESH_BINARY_INV)  \n",
    "\n",
    "#[::+::]==========|============Debug===========|===========================|+|+|+|\\\\\n",
    "    # clkRate= 21\n",
    "    # erodeKernel= np.ones((tick,tick), np.uint8)\n",
    "    # threshLow= 255-tick\n",
    "    # dilateKernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (tick,tick))  \n",
    "    # dilate_i= tick\n",
    "#[\\\\+\\\\]==========|============================|===========================|-|-|-|//\n",
    "\n",
    "    # dilate , more the iteration more the dilation\n",
    "    dilated = cv2.dilate(new_img_inv, dilateKernel, iterations= dilate_i)  \n",
    "\n",
    "\n",
    "    # for cv2.x.x: \n",
    "    # _, contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)  # findContours returns 3 variables for getting contours\n",
    "\n",
    "    # for cv3.x.x  comment above line and uncomment line below:\n",
    "    #image, contours, hierarchy = cv2.findContours(dilated,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # [::]-- Selection: \n",
    "    contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    for contour in contours:\n",
    "        [x, y, w, h] = cv2.boundingRect(contour)\n",
    "\n",
    "        # if w < minW and h < minH:\n",
    "        #     continue\n",
    "        # if w > maxW and h > maxH:\n",
    "        #     continue\n",
    "\n",
    "        if w<maxW and h<maxH and w>minW and h>minH:\n",
    "            # draw rectangle around contour on original image\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 255), 2)\n",
    "            cv2.putText(frame, '[' + str(w)+'x'+str(h)+']', org=(x+w//2, y+h//2), \n",
    "                        fontFace=cv2.FONT_HERSHEY_DUPLEX, \n",
    "                        fontScale=.5, color= bgrCyan, \n",
    "                        thickness=2)\n",
    "        \n",
    " \n",
    "    #cv2.imshow('0 original frame',frame)\n",
    "    cv2.imshow('1 threshold', imgFinal_gray)\n",
    "    cv2.imshow(\"1 grayMask\", grayMask)\n",
    "    # cv2.imshow(\"2  hsvMask\", hsvMask)\n",
    "    # cv2.imshow(\"3 White Text\", new_img)\n",
    "    cv2.imshow(\"4 Black Text\", new_img_inv)\n",
    "    cv2.imshow(\"5 dilated\", dilated)\n",
    "    cv2.imshow(\"6 final\", final)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __[:+:]__ RedMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Cycle:  4\n",
      "[+] Cycle:  3\n",
      "[+] Cycle:  2\n",
      "[+] Cycle:  1\n",
      "[+] Cycle:  0\n",
      "[+] Cycle:  -1\n",
      "[+] Cycle:  -2\n",
      "[+] Cycle:  -3\n",
      "[+] Cycle:  -4\n",
      "[+] Cycle:  -5\n",
      "[+] Cycle:  -6\n"
     ]
    }
   ],
   "source": [
    "gateVid_path= r\"C:\\Users\\richa\\Desktop\\robosubGateCmpl.mp4\"\n",
    "gateImg_path= r\"C:\\Users\\richa\\OneDrive\\CSEC_Robosub\\Data\\gate2.png\"\n",
    "img = cv2.imread(gateImg_path)\n",
    "\n",
    "camNum= 1\n",
    "vidCap = cv2.VideoCapture(gateVid_path)\n",
    "\n",
    "percentile= 98.7\n",
    "minHRatio= .8\n",
    "minWRatio= .8\n",
    "\n",
    "clk= 0\n",
    "clkRate= 1\n",
    "cycLim= 5\n",
    "period= clkRate*255\n",
    "\n",
    "while(True):\n",
    "    # [+:] Read the frame/video. Add the parameter 'cv2.IMREAD_UNCHANGED' to keep cv2 from converting the image to uint8 (assuming it isn't already)\n",
    "        # [+] uint16 can handle negative numbers, uint8 does not. For uint8, it starts counting backwards fromm 255 once you hit -1. \n",
    "    ret, frame = vidCap.read()\n",
    "    if ret==False: \n",
    "        print(\"[x] ERROR: no video frames read\")\n",
    "        break\n",
    "    #final=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # print('frame: ', frame.shape, frame.dtype)\n",
    "\n",
    "    # [+] reduce frame size, maybe for later\n",
    "    #frame= frame[ 60:420, 50:590, :]\n",
    "\n",
    "\n",
    "\n",
    "    # [+:] Extract the B,G, and R channels from the frame, and find the dominant channel\n",
    "    blu_ch= frame[:, :, 0]\n",
    "    grn_ch= frame[:, :, 1]\n",
    "    red_ch = frame[:, :, 2]\n",
    "    bgMax_ch= np.maximum(blu_ch, grn_ch)\n",
    "    max_ch= np.maximum(bgMax_ch, red_ch)\n",
    "    # print('blu_ch: ', blu_ch.shape, blu_ch[0, 0:9])\n",
    "    # print('grn_ch: ', grn_ch.shape, grn_ch[0, 0:9])\n",
    "    # print('red_ch: ', red_ch.shape, red_ch[0, 0:9])l\n",
    "    # print('max_ch: ', max_ch.shape, max_ch[0, 0:9])\n",
    "\n",
    "    # [+:] Find the difference between the red channel and the maximum. The '255' is there to account for uint8 not being able to do negative numbers\n",
    "    diffMat= bgMax_ch-red_ch\n",
    "    redMax= (255-diffMat)\n",
    "    #print('diffMat: ', diffMat.shape, diffMat[0, 0:9])\n",
    "    #print('redMax: ', redMax.shape, redMax[0, 0:10])\n",
    "\n",
    "\n",
    "    # [+:] Find the coordinates of the top x% of the difference matrix\n",
    "    threshold = np.percentile(redMax, percentile)\n",
    "    #print('threshold: ', threshold)\n",
    "\n",
    "\n",
    "    # [+] Creatae a mask in which all elements of redMax that are above the threshold are 1, and the rest are 0\n",
    "    redMask= np.where(redMax>threshold, 1, 0).astype('uint8')\n",
    "  \n",
    "\n",
    "    # [+] Apply mask to the grayscale version of the frame\n",
    "    gray_frame= cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    redZone_frame= cv2.bitwise_and(gray_frame, gray_frame, mask=redMask)\n",
    "\n",
    "\n",
    "    cv2.imshow('frame: ', frame)\n",
    "    cv2.imshow('redZone: ', redZone_frame)\n",
    "\n",
    "    #[+:] Timing Module\n",
    "    clk+=1\n",
    "    tick= clk//clkRate +1\n",
    "    if clk>period: \n",
    "        clk=0\n",
    "        cycLim-=1\n",
    "        print('[+] Cycle: ',cycLim)\n",
    "    # if cycLim<=0: break\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectangle + Trackbars (CVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "frameWidth = 640\n",
    "frameHeight = 480\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, frameWidth)\n",
    "cap.set(4, frameHeight)\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"Trackbars\")\n",
    "cv2.resizeWindow(\"Trackbars\", 640, 240)\n",
    "cv2.createTrackbar(\"Threshold 1\", \"Trackbars\", 14, 255, nothing)\n",
    "cv2.createTrackbar(\"Threshold 2\", \"Trackbars\", 23, 255, nothing)\n",
    "cv2.createTrackbar(\"Area\", \"Trackbars\", 0, 5000, nothing)\n",
    "cv2.createTrackbar(\"maxW\", \"Trackbars\", 1000, 2000, nothing)\n",
    "cv2.createTrackbar(\"minW\", \"Trackbars\", 0, 1000, nothing)\n",
    "cv2.createTrackbar(\"maxH\", \"Trackbars\", 1000, 2000, nothing)\n",
    "cv2.createTrackbar(\"minH\", \"Trackbars\", 0, 1000, nothing)\n",
    "\n",
    "\n",
    "                    \n",
    "def getContours(img, imgContour):\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    #cv2.drawContours(imgContour, contours, -1, (255, 0, 255), 7)\n",
    "    \n",
    "    for cnt in contours:\n",
    "        \"\"\"\n",
    "        area = cv2.contourArea(cnt)\n",
    "        maxArea = cv2.getTrackbarPos(\"Area\", \"Trackbars\")\n",
    "        if area < maxArea:\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255, 0, 255), 7)\n",
    "            peri = cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "            #print(approx)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            cv2.rectangle(imgContour, (x, y), (x + w, y + h), (0, 255, 0), 5)\n",
    "\n",
    "            #cv2.putText(imgContour, \"Points: \" + str(len(approx)), (x + w + 20, y + 20), cv2.FONT_HERSHEY_COMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(imgContour, \"Area: \" + str(int(area)), (x + w + 20, y + 45), cv2.FONT_HERSHEY_COMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \"\"\"\n",
    "        \n",
    "        peri = cv2.arcLength(cnt, True)\n",
    "        area = cv2.contourArea(cnt)\n",
    "        approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "        x, y, w, h = cv2.boundingRect(approx)\n",
    "        maxW = cv2.getTrackbarPos(\"maxW\", \"Trackbars\")\n",
    "        maxH = cv2.getTrackbarPos(\"maxH\", \"Trackbars\")\n",
    "        minW = cv2.getTrackbarPos(\"minW\", \"Trackbars\")\n",
    "        minH = cv2.getTrackbarPos(\"minH\", \"Trackbars\")\n",
    "        if w < maxW and h < maxH and w > minW and h > minH:\n",
    "            cv2.rectangle(imgContour, (x, y), (x + w, y + h), (0, 255, 0), 5)\n",
    "            #cv2.putText(imgContour, \"Points: \" + str(len(approx)), (x + w + 20, y + 20), cv2.FONT_HERSHEY_COMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(imgContour, \"Area: \" + str(int(area)), (x + w + 20, y + 45), cv2.FONT_HERSHEY_COMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "\n",
    "    \n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgContour = img.copy()\n",
    "\n",
    "    imgBlur = cv2.GaussianBlur(img, (7,7), 1)\n",
    "    imgGray = cv2.cvtColor(imgBlur, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    threshold1 = cv2.getTrackbarPos(\"Threshold 1\", \"Trackbars\")\n",
    "    #threshold1 = 14\n",
    "    threshold2 = cv2.getTrackbarPos(\"Threshold 2\", \"Trackbars\")\n",
    "    #threshold2 = 23\n",
    "    imgCanny = cv2.Canny(imgGray, threshold1, threshold2)\n",
    "    #imgCanny = cv2.Canny(imgGray, 143, 102)\n",
    "    kernel = np.ones((5,5))\n",
    "    imgDil = cv2.dilate(imgCanny, kernel, iterations = 1)\n",
    "\n",
    "    getContours(imgDil, imgContour)\n",
    "\n",
    "    imgStack = stackImages(0.8, ([img, imgGray, imgCanny], [imgDil, imgContour, imgContour]))\n",
    "\n",
    "    cv2.imshow(\"Result\", imgStack)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "while True:\n",
    "    ret, capturing = cap.read()\n",
    "    hsv = cv2.cvtColor(capturing, cv2.COLOR_BGR2HSV)\n",
    "    blur = cv2.GaussianBlur(hsv, (7, 7), 0)\n",
    "    edge = cv2.Canny(blur, 100, 100)\n",
    "\n",
    "    # Make it in a way that only shows the shapes and blacks out everything else\n",
    "    ret, thresh1 = cv2.threshold(edge, 220, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow('Original', capturing)\n",
    "    cv2.imshow('Edges', thresh1)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tmp Hat demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_img= r\"C:\\Users\\richa\\OneDrive\\CSEC_Robosub\\Data\\hatDemo.jpg\"\n",
    "\n",
    "\n",
    "filterSize =(3, 3)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, \n",
    "                                   filterSize)\n",
    "  \n",
    "# Reading the image named 'input.jpg'\n",
    "input_image = cv2.imread(input_img)\n",
    "input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "# Applying the Top-Hat operation\n",
    "tophat_img = cv2.morphologyEx(input_image, \n",
    "                              cv2.MORPH_TOPHAT,\n",
    "                              kernel)\n",
    "  \n",
    "cv2.imshow(\"original\", input_image)\n",
    "cv2.imshow(\"tophat\", tophat_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  __[:+:] Tasks__\n",
    "- [x] Gate Task Circle Detection 1\n",
    "- [x] Gate Task Circle Detection 2\n",
    "- [ ] OCR\n",
    "- [ ] Morphological Gradient; gradient = cv.morphologyEx(img, cv.MORPH_GRADIENT, kernel)\n",
    "- [ ] Trimmed Mean\n",
    "- [ ] Box Detection\n",
    "- [ ] Ensemble of Algorithms\n",
    "    - [ ] Helper Functions\n",
    "    - [ ] Polling System\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10065f837bc8873f5387f5268b450066d881a20043fa6c000aa3f801fbe31849"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
